{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c7a17d64",
      "metadata": {
        "id": "c7a17d64"
      },
      "source": [
        "## Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802a0edf",
      "metadata": {
        "id": "802a0edf"
      },
      "source": [
        "#### Libraries need to be installed\n",
        "1) pip install nltk\n",
        "2) pip install banglanltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install banglanltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyJSwtcFsM-5",
        "outputId": "6ef16c1e-2a12-4795-afad-a76eeb32abc7"
      },
      "id": "cyJSwtcFsM-5",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Collecting banglanltk\n",
            "  Downloading banglanltk-0.0.4-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: banglanltk\n",
            "Successfully installed banglanltk-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b083403",
      "metadata": {
        "id": "9b083403"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "49d73427",
      "metadata": {
        "id": "49d73427"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import banglanltk as bn\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import banglanltk\n",
        "print(dir(banglanltk))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpR5fRGH9yDq",
        "outputId": "355a3bd0-1b3d-4e14-aec1-90f02b0e88b3"
      },
      "id": "TpR5fRGH9yDq",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'adjective_suffix', 'clean_text', 'dictPos', 'get_close_matches', 'listSyn', 'noun_suffix', 'pos_tag', 'pronoun_dict', 're', 'sent_tokenize', 'stemmer', 'synonym', 'verb_suffix', 'word_tokenize']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from banglanltk import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "QD9htmEUswrG"
      },
      "id": "QD9htmEUswrG",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "98eab400",
      "metadata": {
        "id": "98eab400"
      },
      "source": [
        "##### Use this data for further processing\n",
        "গতকাল ডিএসইতে ১ হাজার ১৯০ কোটি ২৬ লাখ টাকার শেয়ার লেনদেন হয়েছে। যা আগের দিন থেকে ৫ কোটি ১৫ লাখ! টাকা কম! গতকাল ডি.এসইতে ১ হাজার ১৯৫ কোটি ৪১ লাখ টাকার শেয়ার লেনদেন হয়েছিল। এর আগের দিন মঙ্গলবার ১ হাজার ১৮৩ কোটি টাকা শেয়ার লেনদেন হয়েছিল। বাজার বিশ্লেষণে দেখা যায় ডিএসই প্রধান সূচক ডিএসইএক্স ১২ পয়েন্ট বেড়ে অবস্হান করছে ৬ হাজার ৩১২ পয়েন্টে। অন্য সূচকগুলোর মধ্যে ডিএসইএস বা শরিয়াহ সূচক ৪ পয়েন্ট বেড়ে অবস্হান করছে ১ হাজার ৩৭৫ পয়েন্টে। এছাড়া ডিএস৩০ সূচক ৬ পয়েন্ট বেড়ে দাঁড়িয়েছে ২ হাজার ২৬৫ পয়েন্টে। দেশের প্রধান এই শেয়ারবাজারে গতকাল ৩৮১টি কোম্পানি ও মিউচুয়াল ফান্ডের শেয়ার লেনদেন হয়েছে। এর মধ্যে দর বেড়েছে ১২৯টির। কমেছে ১৯৯টির এবং অপরিবর্তিত রয়েছে ৫৩টির। অপর বাজার চট্টগ্রাম স্টক  এক্সচেঞ্জে সিএসই সিএসই সার্বিক সূচক সিএসপিআই ৭৮ point বেড়েছে। লেনদেন হয়েছে 21 core টাকার শেয়ার।"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "91510354",
      "metadata": {
        "id": "91510354"
      },
      "outputs": [],
      "source": [
        "paragraph = \"গতকাল ডিএসইতে ১ হাজার ১৯০ কোটি ২৬ লাখ টাকার শেয়ার লেনদেন হয়েছে। যা আগের দিন থেকে ৫ কোটি ১৫ লাখ টাকা কম! গতকাল ডি.এসইতে ১ হাজার ১৯৫ কোটি ৪১ লাখ টাকার শেয়ার লেনদেন হয়েছিল। এর আগের দিন মঙ্গলবার ১ হাজার ১৮৩ কোটি টাকা শেয়ার লেনদেন হয়েছিল। বাজার বিশ্লেষণে দেখা যায় ডিএসই প্রধান সূচক ডিএসইএক্স ১২ পয়েন্ট বেড়ে অবস্হান করছে ৬ হাজার ৩১২ পয়েন্টে। অন্য সূচকগুলোর মধ্যে ডিএসইএস বা শরিয়াহ সূচক ৪ পয়েন্ট বেড়ে অবস্হান করছে ১ হাজার ৩৭৫ পয়েন্টে। এছাড়া ডিএস৩০ সূচক ৬ পয়েন্ট বেড়ে দাঁড়িয়েছে ২ হাজার ২৬৫ পয়েন্টে। দেশের প্রধান এই শেয়ারবাজারে গতকাল ৩৮১টি কোম্পানি ও মিউচুয়াল ফান্ডের শেয়ার লেনদেন হয়েছে। এর মধ্যে দর বেড়েছে ১২৯টির। কমেছে ১৯৯টির এবং অপরিবর্তিত রয়েছে ৫৩টির। অপর বাজার চট্টগ্রাম স্টক  এক্সচেঞ্জে সিএসই সিএসই সার্বিক সূচক সিএসপিআই ৭৮ point বেড়েছে। লেনদেন হয়েছে 21 core টাকার শেয়ার।\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae8c701f",
      "metadata": {
        "id": "ae8c701f"
      },
      "source": [
        "#### Tokenizing the words and provide the length (use banglanltk library)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "407aa5af",
      "metadata": {
        "id": "407aa5af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386e5078-de68-4510-f886-d8f3e2cbbbae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['গতকাল', 'ডিএসইতে', '১', 'হাজার', '১৯০', 'কোটি', '২৬', 'লাখ', 'টাকার', 'শেয়ার', 'লেনদেন', 'হয়েছে', 'যা', 'আগের', 'দিন', 'থেকে', '৫', 'কোটি', '১৫', 'লাখ', 'টাকা', 'কম', 'গতকাল', 'ডিএসইতে', '১', 'হাজার', '১৯৫', 'কোটি', '৪১', 'লাখ', 'টাকার', 'শেয়ার', 'লেনদেন', 'হয়েছিল', 'এর', 'আগের', 'দিন', 'মঙ্গলবার', '১', 'হাজার', '১৮৩', 'কোটি', 'টাকা', 'শেয়ার', 'লেনদেন', 'হয়েছিল', 'বাজার', 'বিশ্লেষণে', 'দেখা', 'যায়', 'ডিএসই', 'প্রধান', 'সূচক', 'ডিএসইএক্স', '১২', 'পয়েন্ট', 'বেড়ে', 'অবস্হান', 'করছে', '৬', 'হাজার', '৩১২', 'পয়েন্টে', 'অন্য', 'সূচকগুলোর', 'মধ্যে', 'ডিএসইএস', 'বা', 'শরিয়াহ', 'সূচক', '৪', 'পয়েন্ট', 'বেড়ে', 'অবস্হান', 'করছে', '১', 'হাজার', '৩৭৫', 'পয়েন্টে', 'এছাড়া', 'ডিএস৩০', 'সূচক', '৬', 'পয়েন্ট', 'বেড়ে', 'দাঁড়িয়েছে', '২', 'হাজার', '২৬৫', 'পয়েন্টে', 'দেশের', 'প্রধান', 'এই', 'শেয়ারবাজারে', 'গতকাল', '৩৮১টি', 'কোম্পানি', 'ও', 'মিউচুয়াল', 'ফান্ডের', 'শেয়ার', 'লেনদেন', 'হয়েছে', 'এর', 'মধ্যে', 'দর', 'বেড়েছে', '১২৯টির', 'কমেছে', '১৯৯টির', 'এবং', 'অপরিবর্তিত', 'রয়েছে', '৫৩টির', 'অপর', 'বাজার', 'চট্টগ্রাম', 'স্টক', 'এক্সচেঞ্জে', 'সিএসই', 'সিএসই', 'সার্বিক', 'সূচক', 'সিএসপিআই', '৭৮', 'point', 'বেড়েছে', 'লেনদেন', 'হয়েছে', '21', 'core', 'টাকার', 'শেয়ার']\n"
          ]
        }
      ],
      "source": [
        "# Word Tokenize\n",
        "print(word_tokenize(paragraph))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bab9782d",
      "metadata": {
        "id": "bab9782d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd6675e7-2d5e-468d-a757-485573b18aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133\n"
          ]
        }
      ],
      "source": [
        "# Tokenize Words length\n",
        "print(len(word_tokenize(paragraph)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4bccd6",
      "metadata": {
        "id": "2a4bccd6"
      },
      "source": [
        "**Expected output 133**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a9a2cb6",
      "metadata": {
        "id": "3a9a2cb6"
      },
      "source": [
        "#### Tokenizing the Sentences and provide the length  (use banglanltk library)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3723ef7a",
      "metadata": {
        "id": "3723ef7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dadaa10-5a1f-473b-dd2b-0c3023a65523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['গতকাল ডিএসইতে ১ হাজার ১৯০ কোটি ২৬ লাখ টাকার শেয়ার লেনদেন হয়েছে', 'যা আগের দিন থেকে ৫ কোটি ১৫ লাখ টাকা কম', 'গতকাল ডিএসইতে ১ হাজার ১৯৫ কোটি ৪১ লাখ টাকার শেয়ার লেনদেন হয়েছিল', 'এর আগের দিন মঙ্গলবার ১ হাজার ১৮৩ কোটি টাকা শেয়ার লেনদেন হয়েছিল', 'বাজার বিশ্লেষণে দেখা যায় ডিএসই প্রধান সূচক ডিএসইএক্স ১২ পয়েন্ট বেড়ে অবস্হান করছে ৬ হাজার ৩১২ পয়েন্টে', 'অন্য সূচকগুলোর মধ্যে ডিএসইএস বা শরিয়াহ সূচক ৪ পয়েন্ট বেড়ে অবস্হান করছে ১ হাজার ৩৭৫ পয়েন্টে', 'এছাড়া ডিএস৩০ সূচক ৬ পয়েন্ট বেড়ে দাঁড়িয়েছে ২ হাজার ২৬৫ পয়েন্টে', 'দেশের প্রধান এই শেয়ারবাজারে গতকাল ৩৮১টি কোম্পানি ও মিউচুয়াল ফান্ডের শেয়ার লেনদেন হয়েছে', 'এর মধ্যে দর বেড়েছে ১২৯টির', 'কমেছে ১৯৯টির এবং অপরিবর্তিত রয়েছে ৫৩টির', 'অপর বাজার চট্টগ্রাম স্টক এক্সচেঞ্জে সিএসই সিএসই সার্বিক সূচক সিএসপিআই ৭৮ point বেড়েছে', 'লেনদেন হয়েছে 21 core টাকার শেয়ার']\n"
          ]
        }
      ],
      "source": [
        "# Sentence Tokenize\n",
        "print(sent_tokenize(paragraph))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "adc134cc",
      "metadata": {
        "id": "adc134cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01060d21-f126-4e1b-ff1b-2665b84ece19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ],
      "source": [
        "# Tokenize Sentences length\n",
        "print(len(sent_tokenize(paragraph)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5abb6af5",
      "metadata": {
        "id": "5abb6af5"
      },
      "source": [
        "**Expected output 12**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a26a91",
      "metadata": {
        "id": "04a26a91"
      },
      "source": [
        "#### Apply stopwords and stemmer in the tokenized sentences.\n",
        "###### Use stopwords from \"from nltk.corpus import stopwords\" and stremmer from  \"banglanltk\" package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0d06ca7f",
      "metadata": {
        "id": "0d06ca7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e19013-c8c6-458a-c147-a09c2ebcda5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from banglanltk import stemmer\n",
        "nltk.download('stopwords')\n",
        "stopwords_bangla= set(stopwords.words('bengali'))\n",
        "tokenize_words=word_tokenize(paragraph)\n",
        "tokenize_withoutStopwords=[]\n",
        "for i in tokenize_words:\n",
        "  if i not in stopwords_bangla:\n",
        "    tokenize_withoutStopwords.append(stemmer(i))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ddd7b8e",
      "metadata": {
        "id": "1ddd7b8e"
      },
      "source": [
        "#### Again tokenize the words in sentences that get after applying stopwords and stemming. And provide the length of the tokenize words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6a853972",
      "metadata": {
        "id": "6a853972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ac2617-7bbb-4d22-d223-bda6025d882e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: ['গতকাল', 'ডিএসইতে', '১', 'হাজার', '১৯০', 'কোটি', '২৬', 'লাখ', 'টাকার', 'শেয়ার', 'লেনদেন', 'হয়েছে', 'যা', 'আগের', 'দিন', 'থেকে', '৫', 'কোটি', '১৫', 'লাখ', 'টাকা', 'কম', 'গতকাল', 'ডিএসইতে', '১', 'হাজার', '১৯৫', 'কোটি', '৪১', 'লাখ', 'টাকার', 'শেয়ার', 'লেনদেন', 'হয়েছিল', 'এর', 'আগের', 'দিন', 'মঙ্গলবার', '১', 'হাজার', '১৮৩', 'কোটি', 'টাকা', 'শেয়ার', 'লেনদেন', 'হয়েছিল', 'বাজার', 'বিশ্লেষণে', 'দেখা', 'যায়', 'ডিএসই', 'প্রধান', 'সূচক', 'ডিএসইএক্স', '১২', 'পয়েন্ট', 'বেড়ে', 'অবস্হান', 'করছে', '৬', 'হাজার', '৩১২', 'পয়েন্টে', 'অন্য', 'সূচকগুলোর', 'মধ্যে', 'ডিএসইএস', 'বা', 'শরিয়াহ', 'সূচক', '৪', 'পয়েন্ট', 'বেড়ে', 'অবস্হান', 'করছে', '১', 'হাজার', '৩৭৫', 'পয়েন্টে', 'এছাড়া', 'ডিএস৩০', 'সূচক', '৬', 'পয়েন্ট', 'বেড়ে', 'দাঁড়িয়েছে', '২', 'হাজার', '২৬৫', 'পয়েন্টে', 'দেশের', 'প্রধান', 'এই', 'শেয়ারবাজারে', 'গতকাল', '৩৮১টি', 'কোম্পানি', 'ও', 'মিউচুয়াল', 'ফান্ডের', 'শেয়ার', 'লেনদেন', 'হয়েছে', 'এর', 'মধ্যে', 'দর', 'বেড়েছে', '১২৯টির', 'কমেছে', '১৯৯টির', 'এবং', 'অপরিবর্তিত', 'রয়েছে', '৫৩টির', 'অপর', 'বাজার', 'চট্টগ্রাম', 'স্টক', 'এক্সচেঞ্জে', 'সিএসই', 'সিএসই', 'সার্বিক', 'সূচক', 'সিএসপিআই', '৭৮', 'point', 'বেড়েছে', 'লেনদেন', 'হয়েছে', '21', 'core', 'টাকার', 'শেয়ার']\n",
            "After: ['গতকাল', 'ডিএসইত', '১', '১৯০', 'কে', '২৬', 'লাখ', 'টাকার', 'শেয়ার', 'লেনদে', 'হয়', 'আগের', '৫', 'কে', '১৫', 'লাখ', 'টাকা', 'কম', 'গতকাল', 'ডিএসইত', '১', '১৯৫', 'কে', '৪১', 'লাখ', 'টাকার', 'শেয়ার', 'লেনদে', 'হয়', 'আগের', 'মঙ্গলবার', '১', '১৮৩', 'কে', 'টাকা', 'শেয়ার', 'লেনদে', 'হয়', 'বাজার', 'বিশ্লেষণ', 'যায়', 'ডিএসই', 'প্রধা', 'সূচক', 'ডিএসইএক্স', '১২', 'পয়েন্ট', 'বেড়', 'অবস্হা', '৬', '৩১২', 'পয়েন্ট', 'সূচকগুলোর', 'ডিএসইএস', 'শরিয়াহ', 'সূচক', '৪', 'পয়েন্ট', 'বেড়', 'অবস্হা', '১', '৩৭৫', 'পয়েন্ট', 'এছাড়া', 'ডিএস৩০', 'সূচক', '৬', 'পয়েন্ট', 'বেড়', 'দাঁড়', '২', '২৬৫', 'পয়েন্ট', 'দেশের', 'প্রধা', 'শেয়ারবাজার', 'গতকাল', '৩৮১টি', 'কোম্', 'মিউচুয়াল', 'ফান্ডের', 'শেয়ার', 'লেনদে', 'হয়', 'দর', 'বেড়েছ', '১২৯টির', 'কমেছ', '১৯৯টির', 'অপরিবর্তিত', 'রয়', '৫৩টির', 'অপর', 'বাজার', 'চট্টগ্রাম', 'স্টক', 'এক্সচেঞ্জ', 'সিএসই', 'সিএসই', 'সার্ব', 'সূচক', 'সিএসপিআই', '৭৮', 'point', 'বেড়েছ', 'লেনদে', 'হয়', '21', 'core', 'টাকার', 'শেয়ার']\n"
          ]
        }
      ],
      "source": [
        "# Word Tokenize\n",
        "print(\"Before:\",tokenize_words)\n",
        "print(\"After:\",tokenize_withoutStopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fedeb7c4",
      "metadata": {
        "id": "fedeb7c4",
        "outputId": "e64d7e3d-9444-4b61-835c-496b0c28b463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111\n"
          ]
        }
      ],
      "source": [
        "# Tokenize Words length\n",
        "print(len(tokenize_withoutStopwords))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36c50539",
      "metadata": {
        "id": "36c50539"
      },
      "source": [
        "**Expected output 111**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c705a5f7",
      "metadata": {
        "id": "c705a5f7"
      },
      "source": [
        "### Stemmer Vs Lemamtization\n",
        "Stemming and lemmatization are both techniques used in natural language processing (NLP) and text mining to reduce words to their base or root form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b8aa4639",
      "metadata": {
        "id": "b8aa4639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ab9a8e4-8133-41e1-e314-07317e77de0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Lemmatization: Convert all words into their base form(means present form) & less chance of occuring error.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# What are the differences between Stemmer and Lemmatization(Provive atleast 2 points)\n",
        "'''stremmer: Basically identify the root of words by replacing some portion of the words & High chance of occuring error.'''\n",
        "\n",
        "'''Lemmatization: Convert all words into their base form(means present form) & less chance of occuring error.'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35ffe090",
      "metadata": {
        "id": "35ffe090"
      },
      "source": [
        "Suppose there are some application where we will use Stemming and Lemmatization text processing technique. Tell Us which text processing technique suitable for these applications. Provide answer like **(# Content Filtering -> Stemming)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "11f2fd67",
      "metadata": {
        "id": "11f2fd67"
      },
      "outputs": [],
      "source": [
        "# Sentiment analysis ->\n",
        "# Chatbots application ->\n",
        "# Gmail spam classification ->\n",
        "# Question answer ->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ff066d",
      "metadata": {
        "id": "d7ff066d"
      },
      "source": [
        "### Create Bag of words\n",
        "**1.** Step 1: Cleaning the text that not contain any numeric value, any punctuations etc.(In the give text)\n",
        "\n",
        "**2.** Step 2: Apply stopwords and stemmer again in the clean data.\n",
        "\n",
        "**3.** Step 3: Create Bag of Words (Use \"from sklearn.feature_extraction.text import CountVectorizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7d57715a",
      "metadata": {
        "id": "7d57715a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a75bb9-e53f-46e8-9ee2-4b4ce06b1b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "অপর অপরবরতত অবসহ আগর একসচঞজ এছড কম কমছ ক কম গতকল চটটগরম টক টকর ডএস ডএসই ডএসইএকস ডএসইএস ডএসইত দর দড দশর পরধ পয়নট ফনডর বজর বশলষণ বড বডছ মঙগলবর মউচয়ল যয় রয় লখ লনদ শরয়হ শয়র শয়রবজর সরব সএসই সএসপআই সচক সচকগলর সটক হয়\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "text = '''অপর অপরিবর্তিত অবস্হা আগের এক্সচেঞ্জ এছাড়া কম কমেছ কে কোম্ গতকাল চট্টগ্রাম টাকা টাকার ডিএস ডিএসই ডিএসইএক্স ডিএসইএস ডিএসইত দর দাঁড় দেশের প্রধা পয়েন্ট ফান্ডের বাজার বিশ্লেষণ বেড় বেড়েছ মঙ্গলবার মিউচুয়াল যায় রয় লাখ লেনদে শরিয়াহ শেয়ার শেয়ারবাজার সার্ব সিএসই সিএসপিআই সূচক সূচকগুলোর স্টক হয়'''\n",
        "\n",
        "# Removing numbers\n",
        "text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Removing punctuations\n",
        "text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e53adaf4",
      "metadata": {
        "id": "e53adaf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "ec4eca8e-c916-407a-a501-9ddf2c975eb9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6391113a1861>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbangla_stemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstemmer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# List of stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstopwords_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"এ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ও\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"তার\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Add your stopwords here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bangla_stemmer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from bangla_stemmer.stemmer import stemmer\n",
        "\n",
        "# List of stopwords\n",
        "stopwords_list = [\"এ\", \"ও\", \"তার\", ...]  # Add your stopwords here\n",
        "\n",
        "# Stemming using bangla_stemmer\n",
        "stem = stemmer.BanglaStemmer()\n",
        "stemmed_words = [stem.stem(word) for word in text.split() if word not in stopwords_list]\n",
        "\n",
        "print(stemmed_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "02dd0948",
      "metadata": {
        "id": "02dd0948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "84332c7d-9910-4a24-d69b-fccd71cf8872"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-364a03067881>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert the list of stemmed words back to a single string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocessed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmed_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create the Bag of Words representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stemmed_words' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert the list of stemmed words back to a single string\n",
        "processed_text = ' '.join(stemmed_words)\n",
        "\n",
        "# Create the Bag of Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "bag_of_words = vectorizer.fit_transform([processed_text])\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2e5277f1",
      "metadata": {
        "id": "2e5277f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "1d1ad1f2-04f7-4de6-9e9b-588dc0c74a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b2d8dff7f759>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords_bangla\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mstemmed_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mfiltered_and_stemmed_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmed_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'stem'"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from banglanltk import stemmer\n",
        "import banglanltk\n",
        "\n",
        "# Ensure the stopwords are downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenizing the words\n",
        "tokenized_words = banglanltk.word_tokenize(paragraph)\n",
        "\n",
        "# List of Bangla stopwords\n",
        "stopwords_bangla = set(stopwords.words('bengali'))\n",
        "\n",
        "# Removing stopwords and stemming the words\n",
        "filtered_and_stemmed_words = []\n",
        "for word in tokenized_words:\n",
        "    if word not in stopwords_bangla:\n",
        "        stemmed_word = stemmer.stem(word)\n",
        "        filtered_and_stemmed_words.append(stemmed_word)\n",
        "\n",
        "# Tokenizing the sentences\n",
        "tokenized_sentences = banglanltk.sent_tokenize(paragraph)\n",
        "\n",
        "print(\"Tokenized words length:\", len(tokenized_words))\n",
        "print(\"Filtered and stemmed words length:\", len(filtered_and_stemmed_words))\n",
        "print(\"Tokenized sentences length:\", len(tokenized_sentences))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bba0866",
      "metadata": {
        "id": "3bba0866"
      },
      "source": [
        "###### Expected output\n",
        "array(['অপর', 'অপরিবর্তিত', 'অবস্হা', 'আগের', 'এক্সচেঞ্জ', 'এছাড়া', 'কম',\n",
        "       'কমেছ', 'কে', 'কোম্', 'গতকাল', 'চট্টগ্রাম', 'টাকা', 'টাকার',\n",
        "       'ডিএস', 'ডিএসই', 'ডিএসইএক্স', 'ডিএসইএস', 'ডিএসইত', 'দর', 'দাঁড়',\n",
        "       'দেশের', 'প্রধা', 'পয়েন্ট', 'ফান্ডের', 'বাজার', 'বিশ্লেষণ', 'বেড়',\n",
        "       'বেড়েছ', 'মঙ্গলবার', 'মিউচুয়াল', 'যায়', 'রয়', 'লাখ', 'লেনদে',\n",
        "       'শরিয়াহ', 'শেয়ার', 'শেয়ারবাজার', 'সার্ব', 'সিএসই', 'সিএসপিআই',\n",
        "       'সূচক', 'সূচকগুলোর', 'স্টক', 'হয়'], dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "aa951f94",
      "metadata": {
        "id": "aa951f94"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = '''অপর অপরিবর্তিত অবস্হা আগের এক্সচেঞ্জ এছাড়া কম কমেছ কে কোম্ গতকাল চট্টগ্রাম টাকা টাকার ডিএস ডিএসই ডিএসইএক্স ডিএসইএস ডিএসইত দর দাঁড় দেশের প্রধা পয়েন্ট ফান্ডের বাজার বিশ্লেষণ বেড় বেড়েছ মঙ্গলবার মিউচুয়াল যায় রয় লাখ লেনদে শরিয়াহ শেয়ার শেয়ারবাজার সার্ব সিএসই সিএসপিআই সূচক সূচকগুলোর স্টক হয়'''\n",
        "\n",
        "# Removing numbers\n",
        "text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Removing punctuations\n",
        "text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "41b93b72",
      "metadata": {
        "id": "41b93b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "1376cf49-a4b7-485c-a051-8beb8bc81b21"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-535f3723280b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbangla_stemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstemmer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# List of stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstopwords_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"এ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ও\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"তার\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Add your stopwords here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bangla_stemmer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from bangla_stemmer.stemmer import stemmer\n",
        "\n",
        "# List of stopwords\n",
        "stopwords_list = [\"এ\", \"ও\", \"তার\", ...]  # Add your stopwords here\n",
        "\n",
        "# Stemming using bangla_stemmer\n",
        "stem = stemmer.BanglaStemmer()\n",
        "stemmed_words = [stem.stem(word) for word in text.split() if word not in stopwords_list]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a8099914",
      "metadata": {
        "id": "a8099914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "b75e2422-3e76-4f3f-ba7b-69d29630cb9c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-364a03067881>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert the list of stemmed words back to a single string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocessed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmed_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create the Bag of Words representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stemmed_words' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert the list of stemmed words back to a single string\n",
        "processed_text = ' '.join(stemmed_words)\n",
        "\n",
        "# Create the Bag of Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "bag_of_words = vectorizer.fit_transform([processed_text])\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}