{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c7a17d64",
      "metadata": {
        "id": "c7a17d64"
      },
      "source": [
        "## Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802a0edf",
      "metadata": {
        "id": "802a0edf"
      },
      "source": [
        "#### Libraries need to be installed\n",
        "1) pip install nltk\n",
        "2) pip install banglanltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b083403",
      "metadata": {
        "id": "9b083403"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeV1BWW3vtHO",
        "outputId": "6d093810-e47a-4d78-ed08-5f29288c3940"
      },
      "id": "aeV1BWW3vtHO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install banglanltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdU4mV_evzMN",
        "outputId": "fbdcf33c-589d-4b76-b923-c85f81bedb7b"
      },
      "id": "OdU4mV_evzMN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting banglanltk\n",
            "  Downloading banglanltk-0.0.4-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: banglanltk\n",
            "Successfully installed banglanltk-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49d73427",
      "metadata": {
        "id": "49d73427"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import banglanltk as bn\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98eab400",
      "metadata": {
        "id": "98eab400"
      },
      "source": [
        "##### Use this data for further processing\n",
        "গতকাল ডিএসইতে ১ হাজার ১৯০ কোটি ২৬ লাখ টাকার শেয়ার লেনদেন হয়েছে। যা আগের দিন থেকে ৫ কোটি ১৫ লাখ! টাকা কম! গতকাল ডি.এসইতে ১ হাজার ১৯৫ কোটি ৪১ লাখ টাকার শেয়ার লেনদেন হয়েছিল। এর আগের দিন মঙ্গলবার ১ হাজার ১৮৩ কোটি টাকা শেয়ার লেনদেন হয়েছিল। বাজার বিশ্লেষণে দেখা যায় ডিএসই প্রধান সূচক ডিএসইএক্স ১২ পয়েন্ট বেড়ে অবস্হান করছে ৬ হাজার ৩১২ পয়েন্টে। অন্য সূচকগুলোর মধ্যে ডিএসইএস বা শরিয়াহ সূচক ৪ পয়েন্ট বেড়ে অবস্হান করছে ১ হাজার ৩৭৫ পয়েন্টে। এছাড়া ডিএস৩০ সূচক ৬ পয়েন্ট বেড়ে দাঁড়িয়েছে ২ হাজার ২৬৫ পয়েন্টে। দেশের প্রধান এই শেয়ারবাজারে গতকাল ৩৮১টি কোম্পানি ও মিউচুয়াল ফান্ডের শেয়ার লেনদেন হয়েছে। এর মধ্যে দর বেড়েছে ১২৯টির। কমেছে ১৯৯টির এবং অপরিবর্তিত রয়েছে ৫৩টির। অপর বাজার চট্টগ্রাম স্টক  এক্সচেঞ্জে সিএসই সিএসই সার্বিক সূচক সিএসপিআই ৭৮ point বেড়েছে। লেনদেন হয়েছে 21 core টাকার শেয়ার।"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91510354",
      "metadata": {
        "id": "91510354"
      },
      "outputs": [],
      "source": [
        "paragraph = \"গতকাল ডিএসইতে ১ হাজার ১৯০ কোটি ২৬ লাখ টাকার শেয়ার লেনদেন হয়েছে। যা আগের দিন থেকে ৫ কোটি ১৫ লাখ টাকা কম! গতকাল ডি.এসইতে ১ হাজার ১৯৫ কোটি ৪১ লাখ টাকার শেয়ার লেনদেন হয়েছিল। এর আগের দিন মঙ্গলবার ১ হাজার ১৮৩ কোটি টাকা শেয়ার লেনদেন হয়েছিল। বাজার বিশ্লেষণে দেখা যায় ডিএসই প্রধান সূচক ডিএসইএক্স ১২ পয়েন্ট বেড়ে অবস্হান করছে ৬ হাজার ৩১২ পয়েন্টে। অন্য সূচকগুলোর মধ্যে ডিএসইএস বা শরিয়াহ সূচক ৪ পয়েন্ট বেড়ে অবস্হান করছে ১ হাজার ৩৭৫ পয়েন্টে। এছাড়া ডিএস৩০ সূচক ৬ পয়েন্ট বেড়ে দাঁড়িয়েছে ২ হাজার ২৬৫ পয়েন্টে। দেশের প্রধান এই শেয়ারবাজারে গতকাল ৩৮১টি কোম্পানি ও মিউচুয়াল ফান্ডের শেয়ার লেনদেন হয়েছে। এর মধ্যে দর বেড়েছে ১২৯টির। কমেছে ১৯৯টির এবং অপরিবর্তিত রয়েছে ৫৩টির। অপর বাজার চট্টগ্রাম স্টক  এক্সচেঞ্জে সিএসই সিএসই সার্বিক সূচক সিএসপিআই ৭৮ point বেড়েছে। লেনদেন হয়েছে 21 core টাকার শেয়ার।\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae8c701f",
      "metadata": {
        "id": "ae8c701f"
      },
      "source": [
        "#### Tokenizing the words and provide the length  (use banglanltk library)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407aa5af",
      "metadata": {
        "id": "407aa5af"
      },
      "outputs": [],
      "source": [
        "# Word Tokenize\n",
        "word_tkn = bn.word_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bab9782d",
      "metadata": {
        "id": "bab9782d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884fe87a-bcb8-4161-c6af-a5ac50c25a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133\n"
          ]
        }
      ],
      "source": [
        "# Tokenize Words length\n",
        "word_len = len(word_tkn)\n",
        "\n",
        "print(word_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4bccd6",
      "metadata": {
        "id": "2a4bccd6"
      },
      "source": [
        "**Expected output 133**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a9a2cb6",
      "metadata": {
        "id": "3a9a2cb6"
      },
      "source": [
        "#### Tokenizing the Sentences and provide the length  (use banglanltk library)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3723ef7a",
      "metadata": {
        "id": "3723ef7a"
      },
      "outputs": [],
      "source": [
        "# Sentence Tokenize\n",
        "sen_tkn = bn.sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc134cc",
      "metadata": {
        "id": "adc134cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0998ab-7210-4adf-9d74-a70827bf6a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ],
      "source": [
        "# Tokenize Sentences length\n",
        "sen_len = len(sen_tkn)\n",
        "\n",
        "print(sen_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5abb6af5",
      "metadata": {
        "id": "5abb6af5"
      },
      "source": [
        "**Expected output 12**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a26a91",
      "metadata": {
        "id": "04a26a91"
      },
      "source": [
        "#### Apply stopwords and stemmer in the tokenized sentences.\n",
        "###### Use stopwords from \"from nltk.corpus import stopwords\" and stremmer from  \"banglanltk\" package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbSb-BjVzWaC",
        "outputId": "57d18c02-d459-4602-8b93-c75721e442d4"
      },
      "id": "SbSb-BjVzWaC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d06ca7f",
      "metadata": {
        "id": "0d06ca7f"
      },
      "outputs": [],
      "source": [
        "stp = [word for word in word_tkn if word not in nltk.corpus.stopwords.words('bengali')]\n",
        "stem = [bn.stemmer(word) for word in stp]\n",
        "\n",
        "sentence = ' '.join(stem)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ddd7b8e",
      "metadata": {
        "id": "1ddd7b8e"
      },
      "source": [
        "#### Again tokenize the words in sentences that get after applying stopwords and stemming. And provide the length of the tokenize words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a853972",
      "metadata": {
        "id": "6a853972"
      },
      "outputs": [],
      "source": [
        "# Word Tokenize\n",
        "word_tkn = bn.word_tokenize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fedeb7c4",
      "metadata": {
        "id": "fedeb7c4",
        "outputId": "477290b3-c95f-4abd-f77a-8cf4ff920b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111\n"
          ]
        }
      ],
      "source": [
        "# Tokenize Words length\n",
        "word_len = len(word_tkn)\n",
        "\n",
        "print(word_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36c50539",
      "metadata": {
        "id": "36c50539"
      },
      "source": [
        "**Expected output 111**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c705a5f7",
      "metadata": {
        "id": "c705a5f7"
      },
      "source": [
        "### Stemmer Vs Lemamtization\n",
        "Stemming and lemmatization are both techniques used in natural language processing (NLP) and text mining to reduce words to their base or root form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8aa4639",
      "metadata": {
        "id": "b8aa4639"
      },
      "outputs": [],
      "source": [
        "# What are the differences between Stemmer and Lemmatization(Provide atleast 2 points)\n",
        "# 1. Stemming is rule based approach with low accuracy whereas Lemmatization is dictionary based appoach and provide better accuracy than Stemming\n",
        "# 2. Stemming involves removing prefixes or suffixes from words to obtain a common base form, known as the stem. The resulting stems may not be actual words, and they may not carry the same meaning as the original words. Whereas, Lemmatization involves reducing words to their base, known as the lemma. The lemma is a valid word that represents the canonical form of a word.\n",
        "# 3. Stemming is used when the meaning of the word is not important whereas Lemmatization is used when context of the text is important."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35ffe090",
      "metadata": {
        "id": "35ffe090"
      },
      "source": [
        "Suppose there are some application where we will use Stemming and Lemmatization text processing technique. Tell Us which text processing technique suitable for these applications. Provide answer like **(# Content Filtering -> Stemming)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f2fd67",
      "metadata": {
        "id": "11f2fd67"
      },
      "outputs": [],
      "source": [
        "# Sentiment analysis -> Lemmatization\n",
        "# Chatbots application -> Stemming\n",
        "# Gmail spam classification -> Stemming\n",
        "# Question answer -> Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ff066d",
      "metadata": {
        "id": "d7ff066d"
      },
      "source": [
        "### Create Bag of words\n",
        "**1.** Step 1: Cleaning the text that not contain any numeric value, any punctuations etc.(In the give text)\n",
        "\n",
        "**2.** Step 2: Apply stopwords and stemmer again in the clean data.\n",
        "\n",
        "**3.** Step 3: Create Bag of Words (Use \"from sklearn.feature_extraction.text import CountVectorizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d57715a",
      "metadata": {
        "id": "7d57715a"
      },
      "outputs": [],
      "source": [
        "clean_text = re.sub(r'[^\\u0985-\\u09E0]', ' ', paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53adaf4",
      "metadata": {
        "id": "e53adaf4"
      },
      "outputs": [],
      "source": [
        "word_tkn = bn.word_tokenize(clean_text)\n",
        "stp = [word for word in word_tkn if word not in nltk.corpus.stopwords.words('bengali')]\n",
        "stem = [bn.stemmer(word) for word in word_tkn]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02dd0948",
      "metadata": {
        "id": "02dd0948"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer()\n",
        "bow = vect.fit_transform(stem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5277f1",
      "metadata": {
        "id": "2e5277f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2787493a-f889-4b80-bc3f-3ddee0b14d01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['অন', 'অপর', 'অবস', 'আই', 'আগ', 'উচ', 'এই', 'এক', 'এছ', 'এব', 'এর',\n",
              "       'এস', 'এসই', 'এসইএক', 'এসইএস', 'এসইত', 'এসপ', 'কম', 'কর', 'গতক',\n",
              "       'গলব', 'চক', 'চকগ', 'চট', 'টক', 'টগ', 'দর', 'নদ', 'পয়', 'বর', 'মঙ',\n",
              "       'মধ', 'রধ', 'রব', 'রয়', 'শর', 'ষণ', 'সচ', 'হয়'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bba0866",
      "metadata": {
        "id": "3bba0866"
      },
      "source": [
        "###### Expected output\n",
        "array(['অপর', 'অপরিবর্তিত', 'অবস্হা', 'আগের', 'এক্সচেঞ্জ', 'এছাড়া', 'কম',\n",
        "       'কমেছ', 'কে', 'কোম্', 'গতকাল', 'চট্টগ্রাম', 'টাকা', 'টাকার',\n",
        "       'ডিএস', 'ডিএসই', 'ডিএসইএক্স', 'ডিএসইএস', 'ডিএসইত', 'দর', 'দাঁড়',\n",
        "       'দেশের', 'প্রধা', 'পয়েন্ট', 'ফান্ডের', 'বাজার', 'বিশ্লেষণ', 'বেড়',\n",
        "       'বেড়েছ', 'মঙ্গলবার', 'মিউচুয়াল', 'যায়', 'রয়', 'লাখ', 'লেনদে',\n",
        "       'শরিয়াহ', 'শেয়ার', 'শেয়ারবাজার', 'সার্ব', 'সিএসই', 'সিএসপিআই',\n",
        "       'সূচক', 'সূচকগুলোর', 'স্টক', 'হয়'], dtype=object)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}